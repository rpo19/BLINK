---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.11.4
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
import pandas as pd
import numpy as np

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

import pickle
from sklearn.metrics import confusion_matrix, classification_report
import sklearn

import matplotlib.pyplot as plt
```

```{python}
whole2 = pd.read_csv('', index_col=0)
whole2.head()
```

```{python}
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# train data


class trainData(Dataset):

    def __init__(self, X_data, y_data):
        self.X_data = X_data
        self.y_data = y_data

    def __getitem__(self, index):
        return self.X_data[index], self.y_data[index]

    def __len__(self):
        return len(self.X_data)


class testData(Dataset):

    def __init__(self, X_data):
        self.X_data = X_data

    def __getitem__(self, index):
        return self.X_data[index]

    def __len__(self):
        return len(self.X_data)


class binaryClassification(nn.Module):
    def __init__(self, n):
        super(binaryClassification, self).__init__()
        self.fc1 = nn.Linear(n, 2)
        self.fc2 = nn.Linear(2, 1)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(p=0.1)

    def forward(self, inputs):
        x = self.fc1(inputs)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        #x = nn.Sigmoid(x)

        return x

def binary_acc(y_pred, y_test):
    y_pred_tag = torch.round(torch.sigmoid(y_pred))

    correct_results_sum = (y_pred_tag == y_test).sum().float()
    acc = correct_results_sum/y_test.shape[0]
    acc = torch.round(acc * 100)

    return acc
```

```{python}
def _nrl(datasets, title='nrl', features=['max_cross'], EPOCHS=100, BATCH_SIZE=64, LEARNING_RATE=0.0001):
    print('nrl-{} ...'.format('+'.join(features)))
    for k in ['train', 'train_hard', 'train_aug', 'train_hard_aug']:
        print('train on', k)
        d = datasets[k]
        assert d[features].isna().sum().sum() == 0
        scaler = StandardScaler()

        X_train = d[features].values
        y_train = d['y'].values

        X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.15, random_state=42)

        X_train = scaler.fit_transform(X_train)
        X_validation = scaler.transform(X_validation)

        X_validation = torch.FloatTensor(X_validation)
        y_validation = torch.FloatTensor(y_validation.reshape(-1, 1))

        model = binaryClassification(len(features))
        model.to(device)

        criterion = nn.BCEWithLogitsLoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)

        train_data = trainData(torch.FloatTensor(X_train),
                        torch.FloatTensor(y_train))
        train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)

        model.train()
        for e in range(1, EPOCHS+1):
            epoch_loss = 0
            epoch_acc = 0
            for X_batch, y_batch in train_loader:
                X_batch, y_batch = X_batch.to(device), y_batch.to(device)
                optimizer.zero_grad()

                y_pred = model(X_batch)

                loss = criterion(y_pred, y_batch.unsqueeze(1))

                with torch.no_grad():
                    y_pred_validation = model(X_validation)
                    val_loss = float(F.binary_cross_entropy_with_logits(y_pred_validation, y_validation))

                acc = binary_acc(y_pred, y_batch.unsqueeze(1))

                loss.backward()
                optimizer.step()

                epoch_loss += loss.item()
                epoch_acc += acc.item()

            if e % 5 == 0:
                print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Val Loss: {val_loss:.5f} | Acc: {epoch_acc/len(train_loader):.3f}')

        if _save_models:
            with open(os.path.join(_save_models_path, 'stdscaler+{}+{}.pkl'.format('+'.join(features), k)), 'wb') as fd:
                pickle.dump(scaler, fd)
            torch.save(model.state_dict(), os.path.join(_save_models_path, '{}+{}+{}.torch'.format(title, '+'.join(features), k)))

        for tk in ['test', 'test_hard']:
            print('test on', tk)
            t = datasets[tk]

            X_test = t[features].values
            X_test = scaler.transform(X_test)

            y_test = t['y']

            test_data = testData(torch.FloatTensor(X_test))
            test_loader = DataLoader(dataset=test_data, batch_size=1)

            y_pred_list = []
            model.eval()
            with torch.no_grad():
                for X_batch in test_loader:
                    X_batch = X_batch.to(device)
                    y_test_pred = model(X_batch)
                    y_test_pred = torch.sigmoid(y_test_pred)
                    y_pred_tag = torch.round(y_test_pred)
                    y_pred_list.append(y_pred_tag.cpu().numpy())
            y_pred_list = [a.squeeze().tolist() for a in y_pred_list]

            _temp = pd.DataFrame()
            _temp['y'] = y_test
            _temp['y_pred'] = y_pred_list

            yield _eval(_temp, 'y_pred', title='{}+{}+{}+{}'.format(title, '+'.join(features), k, tk))

```

```{python}
def eval_plot(df):
    print(classification_report(df['y'], df['y_pred_rnd']))
    print('y kde')
    df[['y', 'y_pred']].plot(kind='kde')
    # roc curve
    fpr, tpr, thresholds = sklearn.metrics.roc_curve(df['y'], df['y_pred'])
    pd.DataFrame({
        'tpr': tpr,
        'fpr': fpr,
        'thresholds': thresholds
    }).plot(x='fpr', y='tpr', title='roc curve')
    plt.show()
    print('--- correct ---')
    # correct
    correct = df.query('y == y_pred_rnd')['y_pred']
    correct.plot(kind='density', title='correct kde')
    plt.show()
    correct.plot(kind='hist', title='correct hist')
    plt.show()
    print('correct description:')
    print(correct.describe())
    print('-- errors ---')
    # errors
    errors = df.query('y != y_pred_rnd')['y_pred']
    errors.plot(kind='density', title='errors kde')
    plt.show()
    errors.plot(kind='hist', title='errors hist')
    plt.show()
    print('errors description:')
    print(errors.describe())
```

```{python}
list(whole2.columns)
```

```{python}
nil100_columns = [
 'cross_stats_100_max',
 'cross_stats_100_min',
 'cross_stats_100_mean',
 'cross_stats_100_median',
 'cross_stats_100_stdev',
 'bi_stats_100_max',
 'bi_stats_100_min',
 'bi_stats_100_mean',
 'bi_stats_100_median',
 'bi_stats_100_stdev',
 'cross_jaccard',
 'cross_damerau_levenshtein',
 'bi_jaccard',
 'bi_damerau_levenshtein'
]
```

```{python}
nil10_columns = [
 'cross_stats_10_max',
 'cross_stats_10_min',
 'cross_stats_10_mean',
 'cross_stats_10_median',
 'cross_stats_10_stdev',
 'bi_stats_10_max',
 'bi_stats_10_min',
 'bi_stats_10_mean',
 'bi_stats_10_median',
 'bi_stats_10_stdev',
 'cross_jaccard',
 'cross_damerau_levenshtein',
 'bi_jaccard',
 'bi_damerau_levenshtein'
]
```

```{python}
nil1_columns = [
    'bi_stats_10_max',
    'cross_stats_10_max',
    'cross_jaccard',
    'cross_damerau_levenshtein',
    'bi_jaccard',
    'bi_damerau_levenshtein'
]
```

```{python}
train_df = whole2
```

```{python}
# quando deve essere nil e quando cross sbaglia
train_df['y'] = ((train_df['cross_labels'] != -1) & (train_df['cross_labels'] == train_df['cross_best_candidate'])).astype(int)
```

```{python}
train_df['y'].value_counts()
```

```{python}
train_df, test_df = train_test_split(train_df, test_size=0.33, random_state=17)
```

```{python}
downsample = True

if downsample:
    train_df_0 = train_df.query('y == 0')
    train_df_1 = train_df.query('y == 1')

    train_df_1 = train_df_1.sample(frac=1).iloc[:train_df_0.shape[0]]
    train_df = pd.concat([train_df_0, train_df_1]).sample(frac=1)
```

```{python}
train_df['y'].value_counts()
```

```{python}
print(pd.DataFrame(train_df['y'].value_counts()).to_markdown())
```

```{python}
features = nil1_columns
```

```{python}
X_train = train_df[features].values
y_train = train_df['y'].values
```

```{python}
X_test = test_df[features].values
y_test = test_df['y'].values
```

```{python}
X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.15, random_state=17)
```

```{python}
print(X_train.shape)
print(X_validation.shape)
print(X_test.shape)
```

```{python}
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_validation = scaler.transform(X_validation)

X_validation = torch.FloatTensor(X_validation)
y_validation = torch.FloatTensor(y_validation.reshape(-1, 1))
```

```{python}
X_test = scaler.transform(X_test)
```

```{python}
BATCH_SIZE = 64
LEARNING_RATE = 0.00005
EPOCHS = 200
```

```{python}
loss_df = pd.DataFrame(columns=['loss', 'val_loss', 'acc'])

model = binaryClassification(len(features))
model.to(device)

criterion = nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)

train_data = trainData(torch.FloatTensor(X_train),
                torch.FloatTensor(y_train))
train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)

model.train()
for e in range(1, EPOCHS+1):
    epoch_loss = 0
    epoch_acc = 0
    for X_batch, y_batch in train_loader:
        X_batch, y_batch = X_batch.to(device), y_batch.to(device)
        optimizer.zero_grad()

        y_pred = model(X_batch)

        loss = criterion(y_pred, y_batch.unsqueeze(1))

        with torch.no_grad():
            y_pred_validation = model(X_validation)
            val_loss = float(F.binary_cross_entropy_with_logits(y_pred_validation, y_validation))

        acc = binary_acc(y_pred, y_batch.unsqueeze(1))

        loss.backward()
        optimizer.step()

        epoch_loss += loss.item()
        epoch_acc += acc.item()
        
        loss_df.loc[e] = {
            'loss': epoch_loss/len(train_loader),
            'val_loss': val_loss,
            'acc': epoch_acc/len(train_loader)
        }

    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Val Loss: {val_loss:.5f} | Acc: {epoch_acc/len(train_loader):.3f}')

```

```{python}
loss_df.plot(y=['loss', 'val_loss'])
```

```{python}
model.eval()
y_pred_list = torch.sigmoid(model(torch.FloatTensor(X_test))).cpu().detach().numpy().reshape(-1,)
```

```{python}
eval_df = pd.DataFrame({
    'y': y_test,
    'y_pred': y_pred_list,
    'y_pred_rnd': np.round(y_pred_list)
})
eval_df.head()
```

```{python}
eval_plot(eval_df)
```

```{python}
if False:
    import os
    models_path = 'models_new_20210922'
    if not os.path.isdir(models_path):
        os.mkdir(models_path)
    with open(os.path.join(models_path, 'stdscaler_all_top100.pkl'), 'wb') as fd:
        pickle.dump(scaler, fd)
    torch.save(model.state_dict(), os.path.join(models_path, 'nrl_all_top100.torch'))
```

# lr

```{python}
from sklearn.linear_model import LogisticRegression

from sklearn.ensemble import RandomForestClassifier
```

```{python}
train_df = df
```

```{python}
aida_only = True
if aida_only:
    train_df = whole2#[whole2.apply(lambda x: 'AIDA-YAGO2' in x['src'], axis=1)]
    
    ner_types_p = [
        '../data/BLINK_benchmark_NIL_ner/AIDA-YAGO2_train_ner.jsonl',
        '../data/BLINK_benchmark_NIL_ner/AIDA-YAGO2_testa_ner.jsonl',
        '../data/BLINK_benchmark_NIL_ner/AIDA-YAGO2_testb_ner.jsonl',
    ]
    ner_types = pd.DataFrame()
    for p in ner_types_p:
        ner_types = pd.concat([ner_types, pd.read_json(p, lines=True)])
        
    # one hot
    ner_types[['ner_per', 'ner_loc', 'ner_org', 'ner_misc']] = ner_types.apply(lambda x: {
        'ner_per': x['ner'] == 'PER',
        'ner_loc': x['ner'] == 'LOC',
        'ner_org': x['ner'] == 'ORG',
        'ner_misc': x['ner'] == 'MISC'
    }, axis=1, result_type='expand').astype(int)
        
    wiki_types_p = [
        'wd2ner/AIDA-YAGO2_train.jsonl_ner_type.csv',
        'wd2ner/AIDA-YAGO2_testa.jsonl_ner_type.csv',
        'wd2ner/AIDA-YAGO2_testb.jsonl_ner_type.csv',
    ]
    wiki_types = pd.DataFrame()
    for p in wiki_types_p:
        wiki_types = pd.concat([wiki_types, pd.read_csv(p, index_col=0).astype(int).rename(columns={
            'per': 'wiki_per',
            'loc': 'wiki_loc',
            'org': 'wiki_org',
            'misc': 'wiki_misc',
        })])
        
    assert ner_types.shape[0] == wiki_types.shape[0]
        
    ner_types[wiki_types.columns] = wiki_types
    print(train_df.shape)
    
    train_df = train_df.merge(ner_types[[
        'query_id', 'ner',
        'ner_per', 'ner_loc', 'ner_org', 'ner_misc',
        'wiki_per', 'wiki_loc', 'wiki_org', 'wiki_misc']], on='query_id', how='left')
    
    print(train_df.shape)
```

```{python}
avg_ner = True
if avg_ner:
    # non va bene, serve best candidate
    avg_ner_types_correct = train_df.query('cross_best_candidate == cross_labels').groupby('cross_best_candidate')[['ner_per', 'ner_loc', 'ner_org', 'ner_misc']].mean()
    avg_ner_types_correct = avg_ner_types_correct.rename(columns={
        'ner_per': 'avg_ner_per_correct',
        'ner_loc': 'avg_ner_loc_correct',
        'ner_org': 'avg_ner_org_correct',
        'ner_misc': 'avg_ner_misc_correct',
    })
    
    avg_ner_types = train_df.groupby('cross_best_candidate')[['ner_per', 'ner_loc', 'ner_org', 'ner_misc']].mean()
    avg_ner_types = avg_ner_types.rename(columns={
        'ner_per': 'avg_ner_per',
        'ner_loc': 'avg_ner_loc',
        'ner_org': 'avg_ner_org',
        'ner_misc': 'avg_ner_misc',
    })
    
    #avg_ner_types[['avg_ner_per', 'avg_ner_loc', 'avg_ner_org', 'avg_ner_misc']] = np.array(list(map(lambda x: (x == x.max()).astype(int), avg_ner_types[['avg_ner_per', 'avg_ner_loc', 'avg_ner_org', 'avg_ner_misc']].values)))
    
    train_df = train_df.join(avg_ner_types_correct, on='cross_best_candidate')
    train_df = train_df.join(avg_ner_types, on='cross_best_candidate')
```

```{python}
train_df[train_df['avg_ner_per_correct'].notna()].query('cross_best_candidate != cross_labels')['src'].value_counts()
```

```{python}
whole2.shape
```

```{python}
train_df.shape
```

```{python}
[i for i in list(train_df.columns) if 'nil' in i]
```

```{python}
train_df = train_df.drop(columns=['bi_nil_p',
 'bi_nil_b',
 'bi_best_candidate+nil',
 'cross_nil_p',
 'cross_nil_b',
 'cross_best_candidate+nil',
 'cross_best_candidate+nil_title',
 'bi_best_candidate+nil_title',
 #'cross_nil_p_lr',
 #'cross_nil_b_lr',
])
```

```{python}
#train_df.to_csv('whole3_ner_avg_also_correct.csv')
```

```{python}
if True:
    train_df = train_df[train_df.apply(lambda x: 'AIDA-YAGO2' in x['src'], axis=1)]
    assert train_df[train_df.apply(lambda x: 'AIDA-YAGO2' in x['src'], axis=1)]['ner_per'].isna().sum() == 0
    assert train_df[train_df.apply(lambda x: 'AIDA-YAGO2' in x['src'], axis=1)]['avg_ner_per'].isna().sum() == 0
```

```{python}
train_df[train_df['avg_ner_per_correct'].notna()].query('cross_best_candidate != cross_labels')['src'].value_counts()
```

```{python}
if True:
    train_df = train_df[train_df['avg_ner_per_correct'].notna()]
```

```{python}
train_df.query('cross_labels == -1').shape[0]
```

```{python}
# quando deve essere nil e quando cross sbaglia
train_df['y'] = ((train_df['cross_labels'] != -1) & (train_df['cross_labels'] == train_df['cross_best_candidate'])).astype(int)
```

```{python}
train_df['y'].value_counts()
```

```{python}
train_df, test_df = train_test_split(train_df, test_size=0.33, random_state=17)
```

```{python}
downsample = 'downsample'

if downsample == 'downsample':
    train_df_0 = train_df.query('y == 0')
    train_df_1 = train_df.query('y == 1')

    train_df_1 = train_df_1.sample(frac=1).iloc[:train_df_0.shape[0]]
    train_df = pd.concat([train_df_0, train_df_1]).sample(frac=1)
elif downsample == 'augment':
    pass
```

```{python}
train_df['y'].value_counts()
```

```{python}
# wiki types are biased!!!!
nil10_types_avg = [
    'cross_stats_10_max',
    'cross_stats_10_min',
    'cross_stats_10_mean',
    'cross_stats_10_median',
    'cross_stats_10_stdev',
    'bi_stats_10_max',
    'bi_stats_10_min',
    'bi_stats_10_mean',
    'bi_stats_10_median',
    'bi_stats_10_stdev',
    'cross_hamming',
    'bi_hamming',
    'ner_per',
    'ner_loc',
    'ner_org',
    'ner_misc',
    'avg_ner_per',
    'avg_ner_loc',
    'avg_ner_org',
    'avg_ner_misc',
]
nil10_types_avg_correct = [
    'cross_stats_10_max',
    'cross_stats_10_min',
    'cross_stats_10_mean',
    'cross_stats_10_median',
    'cross_stats_10_stdev',
    'bi_stats_10_max',
    'bi_stats_10_min',
    'bi_stats_10_mean',
    'bi_stats_10_median',
    'bi_stats_10_stdev',
    'cross_hamming',
    'bi_hamming',
    'ner_per',
    'ner_loc',
    'ner_org',
    'ner_misc',
    'avg_ner_per_correct',
    'avg_ner_loc_correct',
    'avg_ner_org_correct',
    'avg_ner_misc_correct',
]
nil1_columns = [
    'bi_stats_10_max',
    'cross_stats_10_max',
    'cross_hamming',
    'bi_hamming',
    'ner_per',
    'ner_loc',
    'ner_org',
    'ner_misc',
    'avg_ner_per',
    'avg_ner_loc',
    'avg_ner_org',
    'avg_ner_misc',
]
nil1_columns_correct = [
    'bi_stats_10_max',
    'cross_stats_10_max',
    'cross_hamming',
    'bi_hamming',
    'ner_per',
    'ner_loc',
    'ner_org',
    'ner_misc',
    'avg_ner_per_correct',
    'avg_ner_loc_correct',
    'avg_ner_org_correct',
    'avg_ner_misc_correct',
]
nil1_columns_bi = [
    'bi_stats_10_max',
    'bi_hamming',
    'ner_per',
    'ner_loc',
    'ner_org',
    'ner_misc',
    'avg_ner_per',
    'avg_ner_loc',
    'avg_ner_org',
    'avg_ner_misc',
]
nil10_columns = [
    'cross_stats_10_max',
    'cross_stats_10_min',
    'cross_stats_10_mean',
    'cross_stats_10_median',
    'cross_stats_10_stdev',
    'bi_stats_10_max',
    'bi_stats_10_min',
    'bi_stats_10_mean',
    'bi_stats_10_median',
    'bi_stats_10_stdev',
    'cross_hamming',
    'bi_hamming',
]
nil10_columns_bi = [
    'bi_stats_10_max',
    'bi_stats_10_min',
    'bi_stats_10_mean',
    'bi_stats_10_median',
    'bi_stats_10_stdev',
    'cross_hamming',
    'bi_hamming',
]
nil100_columns = [
    'cross_stats_100_max',
    'cross_stats_100_min',
    'cross_stats_100_mean',
    'cross_stats_100_median',
    'cross_stats_100_stdev',
    'bi_stats_100_max',
    'bi_stats_100_min',
    'bi_stats_100_mean',
    'bi_stats_100_median',
    'bi_stats_100_stdev',
    'cross_jaccard',
    'cross_damerau_levenshtein',
    'bi_jaccard',
    'bi_damerau_levenshtein'
]
```

```{python}
features = nil1_columns_correct
```

```{python}
train_df[features].isna().sum().sum()
```

```{python}
X_train = train_df[features].values
y_train = train_df['y'].values
```

```{python}
X_test = test_df[features].values
y_test = test_df['y'].values
```

```{python}
#X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.15, random_state=17)
```

```{python}
print(X_train.shape)
#print(X_validation.shape)
print(X_test.shape)
```

```{python}
lr_scaler = StandardScaler()
X_train = lr_scaler.fit_transform(X_train)
```

```{python}
X_test = lr_scaler.transform(X_test)
```

```{python}
_type = 'lr'
if _type == 'lr':
    clf = LogisticRegression(random_state=10, max_iter=200).fit(X_train, y_train)
#if _type == 'rf':
#    clf = RandomForestClassifier(max_depth=2, random_state=0).fit(X_train, y_train)


```

```{python}
clf.predict(X_test)
```

```{python}
y_pred = np.array(list(map(lambda x: x[1], clf.predict_proba(X_test))))
y_pred
```

```{python}
eval_df = pd.DataFrame({
    'y': y_test,
    'y_pred': y_pred,
    'y_pred_rnd': np.round(y_pred)
})
```

```{python}
eval_plot(eval_df)
```

```{python}
tl = 0.25
th = 0.65
print('ratio', eval_df.query(f'y_pred <= {tl} or y_pred >= {th}').shape[0] / eval_df.shape[0])
eval_plot(eval_df.query(f'y_pred <= {tl} or y_pred >= {th}'))
```

```{python}
#whole2['cross_nil_p'] = 
whole2['cross_nil_p_lr'] = np.array(
    list(
        map(
            lambda x: x[1],
            clf.predict_proba(
                lr_scaler.transform(whole2[features].values)
            )
        )
    )
)
```

```{python}
whole2['cross_nil_b_lr'] = np.round(whole2['cross_nil_p_lr'])
```

```{python}
print(classification_report(whole2['y'], whole2['cross_nil_b']))
```

```{python}
print(classification_report(whole2['y'], whole2['cross_nil_b_lr']))
```

```{python}
def _myf(x):
    if x['cross_nil_b_lr'] == 0:
        return -1
    else:
        return x['cross_best_candidate']

whole2['cross_best_candidate_nil_lr'] = whole2.apply(_myf, axis=1)
```

```{python}
whole2.query('cross_labels == `cross_best_candidate+nil`').shape[0] / whole2.shape[0]
```

```{python}
whole2.query('cross_labels == `cross_best_candidate_nil_lr`').shape[0] / whole2.shape[0]
```

```{python}
whole2.query('cross_labels != -1 and cross_labels == cross_best_candidate and cross_nil_b == 0').shape[0]  / whole2.shape[0]
```

```{python}
whole2.query('cross_labels != -1 and cross_labels == cross_best_candidate and cross_nil_b == 0')['cross_hamming'].plot(kind='density')
```

```{python}
wrong_nil = whole2.query('cross_labels != -1 and cross_labels == cross_best_candidate and cross_nil_b_lr == 0')
```

```{python}
wrong_nil.shape[0] / whole2.shape[0]
```

```{python}
import textdistance
```

```{python}
dfun = textdistance.hamming.normalized_similarity
```

```{python}
wrong_nil.apply(
    lambda x: dfun(x['mention'], x['cross_best_candidate_title']),
    axis=1
).plot(kind='density')
```

```{python}
wrong_nil['cross_nil_p_lr'].plot(kind='density')
```

```{python}
wrong_nil['cross_nil_p_lr'].plot(kind='density')
```

```{python}
whole2.apply(
    lambda x: dfun(x['mention'], x['cross_best_candidate_title']),
    axis=1
).plot(kind='density')
```

```{python}
whole2['cross_hamming'] = whole2.apply(
    lambda x: textdistance.hamming.normalized_similarity(x['mention'], x['cross_best_candidate_title']),
    axis=1
)
```

```{python}
whole2['bi_hamming'] = whole2.apply(
    lambda x: textdistance.hamming.normalized_similarity(x['mention'], x['bi_best_candidate_title']),
    axis=1
)
```

```{python}
whole2.
```

```{python}
whole2.to_csv('whole2_with_100_10_stats_ds.csv')
```

```{python}
whole2
```

```{python}
from flair.data import Sentence
from flair.models import SequenceTagger

# make a sentence
sentence = Sentence('I love Berlin .')

# load the NER tagger
tagger = SequenceTagger.load('ner')

# run NER over sentence
tagger.predict(sentence)
```

```{python}
# ls
```

```{python}
df = pd.read_csv('whole3_ner_avg_also_correct.csv', index_col=0)
```

```{python}
df['src'].value_counts()
```

```{python}
[
    {
        'train': ['dataset_and_preds/AIDA-YAGO2_train.csv'],
        'test': ['dataset_and_preds/AIDA-YAGO2_testa.csv', 'dataset_and_preds/AIDA-YAGO2_testb.csv'],
        'augment': 'no',
        'features': 'all'
    },
    {
        'train': ['dataset_and_preds/AIDA-YAGO2_train.csv'],
        'test': ['dataset_and_preds/AIDA-YAGO2_testa.csv', 'dataset_and_preds/AIDA-YAGO2_testb.csv'],
        'augment': 'augment'
        'features': 'all'
    },
    {
        'train': ['dataset_and_preds/AIDA-YAGO2_train.csv'],
        'test': ['dataset_and_preds/AIDA-YAGO2_testa.csv', 'dataset_and_preds/AIDA-YAGO2_testb.csv'],
        'augment': 'undersample'
        'features': 'all'
    },
]
```

```{python}
df[df['src'].isin(['dataset_and_preds/AIDA-YAGO2_testa.csv', 'dataset_and_preds/AIDA-YAGO2_testb.csv'])]['src'].value_counts()
```

```{python}
isinstance([4.0], list)
```

```{python}
df['y']
```

```{python}
train_df[['avg_ner_per_correct', 'avg_ner_org_correct']].notna().all(axis=1)
```

```{python}
train_df[train_df[['avg_ner_per_correct', 'avg_ner_org_correct']].notna().all(axis=1)].isna().sum()
```

```{python}
train_df.to_csv('whole3_ner_avg_also_correct2.csv')
```

```{python}
list(dataset.columns)
```

```{python}
train_df = train_df.rename(columns={
    'avg_ner_misc': 'avg_ner_misc_cross'
})
```

```{python}
list(train_df.columns)
```

```{python}
# non va bene, serve best candidate
avg_ner_types_correct = train_df.query('bi_best_candidate == bi_labels').groupby('bi_best_candidate')[['ner_per', 'ner_loc', 'ner_org', 'ner_misc']].mean()
avg_ner_types_correct = avg_ner_types_correct.rename(columns={
    'ner_per': 'avg_ner_per_correct_bi',
    'ner_loc': 'avg_ner_loc_correct_bi',
    'ner_org': 'avg_ner_org_correct_bi',
    'ner_misc': 'avg_ner_misc_correct_bi',
})

avg_ner_types = train_df.groupby('bi_best_candidate')[['ner_per', 'ner_loc', 'ner_org', 'ner_misc']].mean()
avg_ner_types = avg_ner_types.rename(columns={
    'ner_per': 'avg_ner_per_bi',
    'ner_loc': 'avg_ner_loc_bi',
    'ner_org': 'avg_ner_org_bi',
    'ner_misc': 'avg_ner_misc_bi',
})

#avg_ner_types[['avg_ner_per', 'avg_ner_loc', 'avg_ner_org', 'avg_ner_misc']] = np.array(list(map(lambda x: (x == x.max()).astype(int), avg_ner_types[['avg_ner_per', 'avg_ner_loc', 'avg_ner_org', 'avg_ner_misc']].values)))

train_df = train_df.join(avg_ner_types_correct, on='bi_best_candidate')
train_df = train_df.join(avg_ner_types, on='bi_best_candidate')
```

```{python}
dataset['src'].value_counts().index.tolist()
```

```{python}
dataset.columns
```

```{python}
dataset.query('(y_pred == 1 and (cross_labels == cross_best_candidate or Wikipedia_title == cross_best_candidate_title)) or (cross_labels == -1 and y_pred == 0)')
```
