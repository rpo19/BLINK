---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.11.4
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
import pandas as pd
import numpy as np

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

import pickle
from sklearn.metrics import confusion_matrix, classification_report
import sklearn

import matplotlib.pyplot as plt

import seaborn as sns
```

```{python}
whole2 = pd.read_csv('', index_col=0)
whole2.head()
```

```{python}
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# train data


class trainData(Dataset):

    def __init__(self, X_data, y_data):
        self.X_data = X_data
        self.y_data = y_data

    def __getitem__(self, index):
        return self.X_data[index], self.y_data[index]

    def __len__(self):
        return len(self.X_data)


class testData(Dataset):

    def __init__(self, X_data):
        self.X_data = X_data

    def __getitem__(self, index):
        return self.X_data[index]

    def __len__(self):
        return len(self.X_data)


class binaryClassification(nn.Module):
    def __init__(self, n):
        super(binaryClassification, self).__init__()
        self.fc1 = nn.Linear(n, 2)
        self.fc2 = nn.Linear(2, 1)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(p=0.1)

    def forward(self, inputs):
        x = self.fc1(inputs)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        #x = nn.Sigmoid(x)

        return x

def binary_acc(y_pred, y_test):
    y_pred_tag = torch.round(torch.sigmoid(y_pred))

    correct_results_sum = (y_pred_tag == y_test).sum().float()
    acc = correct_results_sum/y_test.shape[0]
    acc = torch.round(acc * 100)

    return acc
```

```{python}
def _nrl(datasets, title='nrl', features=['max_cross'], EPOCHS=100, BATCH_SIZE=64, LEARNING_RATE=0.0001):
    print('nrl-{} ...'.format('+'.join(features)))
    for k in ['train', 'train_hard', 'train_aug', 'train_hard_aug']:
        print('train on', k)
        d = datasets[k]
        assert d[features].isna().sum().sum() == 0
        scaler = StandardScaler()

        X_train = d[features].values
        y_train = d['y'].values

        X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.15, random_state=42)

        X_train = scaler.fit_transform(X_train)
        X_validation = scaler.transform(X_validation)

        X_validation = torch.FloatTensor(X_validation)
        y_validation = torch.FloatTensor(y_validation.reshape(-1, 1))

        model = binaryClassification(len(features))
        model.to(device)

        criterion = nn.BCEWithLogitsLoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)

        train_data = trainData(torch.FloatTensor(X_train),
                        torch.FloatTensor(y_train))
        train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)

        model.train()
        for e in range(1, EPOCHS+1):
            epoch_loss = 0
            epoch_acc = 0
            for X_batch, y_batch in train_loader:
                X_batch, y_batch = X_batch.to(device), y_batch.to(device)
                optimizer.zero_grad()

                y_pred = model(X_batch)

                loss = criterion(y_pred, y_batch.unsqueeze(1))

                with torch.no_grad():
                    y_pred_validation = model(X_validation)
                    val_loss = float(F.binary_cross_entropy_with_logits(y_pred_validation, y_validation))

                acc = binary_acc(y_pred, y_batch.unsqueeze(1))

                loss.backward()
                optimizer.step()

                epoch_loss += loss.item()
                epoch_acc += acc.item()

            if e % 5 == 0:
                print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Val Loss: {val_loss:.5f} | Acc: {epoch_acc/len(train_loader):.3f}')

        if _save_models:
            with open(os.path.join(_save_models_path, 'stdscaler+{}+{}.pkl'.format('+'.join(features), k)), 'wb') as fd:
                pickle.dump(scaler, fd)
            torch.save(model.state_dict(), os.path.join(_save_models_path, '{}+{}+{}.torch'.format(title, '+'.join(features), k)))

        for tk in ['test', 'test_hard']:
            print('test on', tk)
            t = datasets[tk]

            X_test = t[features].values
            X_test = scaler.transform(X_test)

            y_test = t['y']

            test_data = testData(torch.FloatTensor(X_test))
            test_loader = DataLoader(dataset=test_data, batch_size=1)

            y_pred_list = []
            model.eval()
            with torch.no_grad():
                for X_batch in test_loader:
                    X_batch = X_batch.to(device)
                    y_test_pred = model(X_batch)
                    y_test_pred = torch.sigmoid(y_test_pred)
                    y_pred_tag = torch.round(y_test_pred)
                    y_pred_list.append(y_pred_tag.cpu().numpy())
            y_pred_list = [a.squeeze().tolist() for a in y_pred_list]

            _temp = pd.DataFrame()
            _temp['y'] = y_test
            _temp['y_pred'] = y_pred_list

            yield _eval(_temp, 'y_pred', title='{}+{}+{}+{}'.format(title, '+'.join(features), k, tk))

```

```{python}
def eval_plot(df):
    print(classification_report(df['y'], df['y_pred_rnd']))
    print('y kde')
    df[['y', 'y_pred']].plot(kind='kde')
    # roc curve
    fpr, tpr, thresholds = sklearn.metrics.roc_curve(df['y'], df['y_pred'])
    pd.DataFrame({
        'tpr': tpr,
        'fpr': fpr,
        'thresholds': thresholds
    }).plot(x='fpr', y='tpr', title='roc curve')
    plt.show()
    print('--- correct ---')
    # correct
    correct = df.query('y == y_pred_rnd')['y_pred']
    correct.plot(kind='density', title='correct kde')
    plt.show()
    correct.plot(kind='hist', title='correct hist')
    plt.show()
    print('correct description:')
    print(correct.describe())
    print('-- errors ---')
    # errors
    errors = df.query('y != y_pred_rnd')['y_pred']
    errors.plot(kind='density', title='errors kde')
    plt.show()
    errors.plot(kind='hist', title='errors hist')
    plt.show()
    print('errors description:')
    print(errors.describe())
```

```{python}
list(whole2.columns)
```

```{python}
nil100_columns = [
 'cross_stats_100_max',
 'cross_stats_100_min',
 'cross_stats_100_mean',
 'cross_stats_100_median',
 'cross_stats_100_stdev',
 'bi_stats_100_max',
 'bi_stats_100_min',
 'bi_stats_100_mean',
 'bi_stats_100_median',
 'bi_stats_100_stdev',
 'cross_jaccard',
 'cross_damerau_levenshtein',
 'bi_jaccard',
 'bi_damerau_levenshtein'
]
```

```{python}
nil10_columns = [
 'cross_stats_10_max',
 'cross_stats_10_min',
 'cross_stats_10_mean',
 'cross_stats_10_median',
 'cross_stats_10_stdev',
 'bi_stats_10_max',
 'bi_stats_10_min',
 'bi_stats_10_mean',
 'bi_stats_10_median',
 'bi_stats_10_stdev',
 'cross_jaccard',
 'cross_damerau_levenshtein',
 'bi_jaccard',
 'bi_damerau_levenshtein'
]
```

```{python}
nil1_columns = [
    'bi_stats_10_max',
    'cross_stats_10_max',
    'cross_jaccard',
    'cross_damerau_levenshtein',
    'bi_jaccard',
    'bi_damerau_levenshtein'
]
```

```{python}
train_df = whole2
```

```{python}
# quando deve essere nil e quando cross sbaglia
train_df['y'] = ((train_df['cross_labels'] != -1) & (train_df['cross_labels'] == train_df['cross_best_candidate'])).astype(int)
```

```{python}
train_df['y'].value_counts()
```

```{python}
train_df, test_df = train_test_split(train_df, test_size=0.33, random_state=17)
```

```{python}
downsample = True

if downsample:
    train_df_0 = train_df.query('y == 0')
    train_df_1 = train_df.query('y == 1')

    train_df_1 = train_df_1.sample(frac=1).iloc[:train_df_0.shape[0]]
    train_df = pd.concat([train_df_0, train_df_1]).sample(frac=1)
```

```{python}
train_df['y'].value_counts()
```

```{python}
print(pd.DataFrame(train_df['y'].value_counts()).to_markdown())
```

```{python}
features = nil1_columns
```

```{python}
X_train = train_df[features].values
y_train = train_df['y'].values
```

```{python}
X_test = test_df[features].values
y_test = test_df['y'].values
```

```{python}
X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.15, random_state=17)
```

```{python}
print(X_train.shape)
print(X_validation.shape)
print(X_test.shape)
```

```{python}
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_validation = scaler.transform(X_validation)

X_validation = torch.FloatTensor(X_validation)
y_validation = torch.FloatTensor(y_validation.reshape(-1, 1))
```

```{python}
X_test = scaler.transform(X_test)
```

```{python}
BATCH_SIZE = 64
LEARNING_RATE = 0.00005
EPOCHS = 200
```

```{python}
loss_df = pd.DataFrame(columns=['loss', 'val_loss', 'acc'])

model = binaryClassification(len(features))
model.to(device)

criterion = nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)

train_data = trainData(torch.FloatTensor(X_train),
                torch.FloatTensor(y_train))
train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)

model.train()
for e in range(1, EPOCHS+1):
    epoch_loss = 0
    epoch_acc = 0
    for X_batch, y_batch in train_loader:
        X_batch, y_batch = X_batch.to(device), y_batch.to(device)
        optimizer.zero_grad()

        y_pred = model(X_batch)

        loss = criterion(y_pred, y_batch.unsqueeze(1))

        with torch.no_grad():
            y_pred_validation = model(X_validation)
            val_loss = float(F.binary_cross_entropy_with_logits(y_pred_validation, y_validation))

        acc = binary_acc(y_pred, y_batch.unsqueeze(1))

        loss.backward()
        optimizer.step()

        epoch_loss += loss.item()
        epoch_acc += acc.item()
        
        loss_df.loc[e] = {
            'loss': epoch_loss/len(train_loader),
            'val_loss': val_loss,
            'acc': epoch_acc/len(train_loader)
        }

    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Val Loss: {val_loss:.5f} | Acc: {epoch_acc/len(train_loader):.3f}')

```

```{python}
loss_df.plot(y=['loss', 'val_loss'])
```

```{python}
model.eval()
y_pred_list = torch.sigmoid(model(torch.FloatTensor(X_test))).cpu().detach().numpy().reshape(-1,)
```

```{python}
eval_df = pd.DataFrame({
    'y': y_test,
    'y_pred': y_pred_list,
    'y_pred_rnd': np.round(y_pred_list)
})
eval_df.head()
```

```{python}
eval_plot(eval_df)
```

```{python}
if False:
    import os
    models_path = 'models_new_20210922'
    if not os.path.isdir(models_path):
        os.mkdir(models_path)
    with open(os.path.join(models_path, 'stdscaler_all_top100.pkl'), 'wb') as fd:
        pickle.dump(scaler, fd)
    torch.save(model.state_dict(), os.path.join(models_path, 'nrl_all_top100.torch'))
```

# lr

```{python}
from sklearn.linear_model import LogisticRegression

from sklearn.ensemble import RandomForestClassifier
```

```{python}
train_df = df
```

```{python}
aida_only = True
if aida_only:
    train_df = whole2#[whole2.apply(lambda x: 'AIDA-YAGO2' in x['src'], axis=1)]
    
    ner_types_p = [
        '../data/BLINK_benchmark_NIL_ner/AIDA-YAGO2_train_ner.jsonl',
        '../data/BLINK_benchmark_NIL_ner/AIDA-YAGO2_testa_ner.jsonl',
        '../data/BLINK_benchmark_NIL_ner/AIDA-YAGO2_testb_ner.jsonl',
    ]
    ner_types = pd.DataFrame()
    for p in ner_types_p:
        ner_types = pd.concat([ner_types, pd.read_json(p, lines=True)])
        
    # one hot
    ner_types[['ner_per', 'ner_loc', 'ner_org', 'ner_misc']] = ner_types.apply(lambda x: {
        'ner_per': x['ner'] == 'PER',
        'ner_loc': x['ner'] == 'LOC',
        'ner_org': x['ner'] == 'ORG',
        'ner_misc': x['ner'] == 'MISC'
    }, axis=1, result_type='expand').astype(int)
        
    wiki_types_p = [
        'wd2ner/AIDA-YAGO2_train.jsonl_ner_type.csv',
        'wd2ner/AIDA-YAGO2_testa.jsonl_ner_type.csv',
        'wd2ner/AIDA-YAGO2_testb.jsonl_ner_type.csv',
    ]
    wiki_types = pd.DataFrame()
    for p in wiki_types_p:
        wiki_types = pd.concat([wiki_types, pd.read_csv(p, index_col=0).astype(int).rename(columns={
            'per': 'wiki_per',
            'loc': 'wiki_loc',
            'org': 'wiki_org',
            'misc': 'wiki_misc',
        })])
        
    assert ner_types.shape[0] == wiki_types.shape[0]
        
    ner_types[wiki_types.columns] = wiki_types
    print(train_df.shape)
    
    train_df = train_df.merge(ner_types[[
        'query_id', 'ner',
        'ner_per', 'ner_loc', 'ner_org', 'ner_misc',
        'wiki_per', 'wiki_loc', 'wiki_org', 'wiki_misc']], on='query_id', how='left')
    
    print(train_df.shape)
```

```{python}
avg_ner = True
if avg_ner:
    # non va bene, serve best candidate
    avg_ner_types_correct = train_df.query('cross_best_candidate == cross_labels').groupby('cross_best_candidate')[['ner_per', 'ner_loc', 'ner_org', 'ner_misc']].mean()
    avg_ner_types_correct = avg_ner_types_correct.rename(columns={
        'ner_per': 'avg_ner_per_correct',
        'ner_loc': 'avg_ner_loc_correct',
        'ner_org': 'avg_ner_org_correct',
        'ner_misc': 'avg_ner_misc_correct',
    })
    
    avg_ner_types = train_df.groupby('cross_best_candidate')[['ner_per', 'ner_loc', 'ner_org', 'ner_misc']].mean()
    avg_ner_types = avg_ner_types.rename(columns={
        'ner_per': 'avg_ner_per',
        'ner_loc': 'avg_ner_loc',
        'ner_org': 'avg_ner_org',
        'ner_misc': 'avg_ner_misc',
    })
    
    #avg_ner_types[['avg_ner_per', 'avg_ner_loc', 'avg_ner_org', 'avg_ner_misc']] = np.array(list(map(lambda x: (x == x.max()).astype(int), avg_ner_types[['avg_ner_per', 'avg_ner_loc', 'avg_ner_org', 'avg_ner_misc']].values)))
    
    train_df = train_df.join(avg_ner_types_correct, on='cross_best_candidate')
    train_df = train_df.join(avg_ner_types, on='cross_best_candidate')
```

```{python}
train_df[train_df['avg_ner_per_correct'].notna()].query('cross_best_candidate != cross_labels')['src'].value_counts()
```

```{python}
whole2.shape
```

```{python}
train_df.shape
```

```{python}
[i for i in list(train_df.columns) if 'nil' in i]
```

```{python}
train_df = train_df.drop(columns=['bi_nil_p',
 'bi_nil_b',
 'bi_best_candidate+nil',
 'cross_nil_p',
 'cross_nil_b',
 'cross_best_candidate+nil',
 'cross_best_candidate+nil_title',
 'bi_best_candidate+nil_title',
 #'cross_nil_p_lr',
 #'cross_nil_b_lr',
])
```

```{python}
#train_df.to_csv('whole3_ner_avg_also_correct.csv')
```

```{python}
if True:
    train_df = train_df[train_df.apply(lambda x: 'AIDA-YAGO2' in x['src'], axis=1)]
    assert train_df[train_df.apply(lambda x: 'AIDA-YAGO2' in x['src'], axis=1)]['ner_per'].isna().sum() == 0
    assert train_df[train_df.apply(lambda x: 'AIDA-YAGO2' in x['src'], axis=1)]['avg_ner_per'].isna().sum() == 0
```

```{python}
train_df[train_df['avg_ner_per_correct'].notna()].query('cross_best_candidate != cross_labels')['src'].value_counts()
```

```{python}
if True:
    train_df = train_df[train_df['avg_ner_per_correct'].notna()]
```

```{python}
train_df.query('cross_labels == -1').shape[0]
```

```{python}
# quando deve essere nil e quando cross sbaglia
train_df['y'] = ((train_df['cross_labels'] != -1) & (train_df['cross_labels'] == train_df['cross_best_candidate'])).astype(int)
```

```{python}
train_df['y'].value_counts()
```

```{python}
train_df, test_df = train_test_split(train_df, test_size=0.33, random_state=17)
```

```{python}
downsample = 'downsample'

if downsample == 'downsample':
    train_df_0 = train_df.query('y == 0')
    train_df_1 = train_df.query('y == 1')

    train_df_1 = train_df_1.sample(frac=1).iloc[:train_df_0.shape[0]]
    train_df = pd.concat([train_df_0, train_df_1]).sample(frac=1)
elif downsample == 'augment':
    pass
```

```{python}
train_df['y'].value_counts()
```

```{python}
# wiki types are biased!!!!
nil10_types_avg = [
    'cross_stats_10_max',
    'cross_stats_10_min',
    'cross_stats_10_mean',
    'cross_stats_10_median',
    'cross_stats_10_stdev',
    'bi_stats_10_max',
    'bi_stats_10_min',
    'bi_stats_10_mean',
    'bi_stats_10_median',
    'bi_stats_10_stdev',
    'cross_hamming',
    'bi_hamming',
    'ner_per',
    'ner_loc',
    'ner_org',
    'ner_misc',
    'avg_ner_per',
    'avg_ner_loc',
    'avg_ner_org',
    'avg_ner_misc',
]
nil10_types_avg_correct = [
    'cross_stats_10_max',
    'cross_stats_10_min',
    'cross_stats_10_mean',
    'cross_stats_10_median',
    'cross_stats_10_stdev',
    'bi_stats_10_max',
    'bi_stats_10_min',
    'bi_stats_10_mean',
    'bi_stats_10_median',
    'bi_stats_10_stdev',
    'cross_hamming',
    'bi_hamming',
    'ner_per',
    'ner_loc',
    'ner_org',
    'ner_misc',
    'avg_ner_per_correct',
    'avg_ner_loc_correct',
    'avg_ner_org_correct',
    'avg_ner_misc_correct',
]
nil1_columns = [
    'bi_stats_10_max',
    'cross_stats_10_max',
    'cross_hamming',
    'bi_hamming',
    'ner_per',
    'ner_loc',
    'ner_org',
    'ner_misc',
    'avg_ner_per',
    'avg_ner_loc',
    'avg_ner_org',
    'avg_ner_misc',
]
nil1_columns_correct = [
    'bi_stats_10_max',
    'cross_stats_10_max',
    'cross_hamming',
    'bi_hamming',
    'ner_per',
    'ner_loc',
    'ner_org',
    'ner_misc',
    'avg_ner_per_correct',
    'avg_ner_loc_correct',
    'avg_ner_org_correct',
    'avg_ner_misc_correct',
]
nil1_columns_bi = [
    'bi_stats_10_max',
    'bi_hamming',
    'ner_per',
    'ner_loc',
    'ner_org',
    'ner_misc',
    'avg_ner_per',
    'avg_ner_loc',
    'avg_ner_org',
    'avg_ner_misc',
]
nil10_columns = [
    'cross_stats_10_max',
    'cross_stats_10_min',
    'cross_stats_10_mean',
    'cross_stats_10_median',
    'cross_stats_10_stdev',
    'bi_stats_10_max',
    'bi_stats_10_min',
    'bi_stats_10_mean',
    'bi_stats_10_median',
    'bi_stats_10_stdev',
    'cross_hamming',
    'bi_hamming',
]
nil10_columns_bi = [
    'bi_stats_10_max',
    'bi_stats_10_min',
    'bi_stats_10_mean',
    'bi_stats_10_median',
    'bi_stats_10_stdev',
    'cross_hamming',
    'bi_hamming',
]
nil100_columns = [
    'cross_stats_100_max',
    'cross_stats_100_min',
    'cross_stats_100_mean',
    'cross_stats_100_median',
    'cross_stats_100_stdev',
    'bi_stats_100_max',
    'bi_stats_100_min',
    'bi_stats_100_mean',
    'bi_stats_100_median',
    'bi_stats_100_stdev',
    'cross_jaccard',
    'cross_damerau_levenshtein',
    'bi_jaccard',
    'bi_damerau_levenshtein'
]
```

```{python}
features = nil10_columns
```

```{python}
train_df[features].isna().sum().sum()
```

```{python}
X_train = train_df[features].values
y_train = train_df['y'].values
```

```{python}
X_test = test_df[features].values
y_test = test_df['y'].values
```

```{python}
#X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.15, random_state=17)
```

```{python}
print(X_train.shape)
#print(X_validation.shape)
print(X_test.shape)
```

```{python}
lr_scaler = StandardScaler()
X_train = lr_scaler.fit_transform(X_train)
```

```{python}
X_test = lr_scaler.transform(X_test)
```

```{python}
_type = 'lr'
if _type == 'lr':
    clf = LogisticRegression(random_state=10, max_iter=200).fit(X_train, y_train)
#if _type == 'rf':
#    clf = RandomForestClassifier(max_depth=2, random_state=0).fit(X_train, y_train)


```

```{python}
clf.predict(X_test)
```

```{python}
y_pred = np.array(list(map(lambda x: x[1], clf.predict_proba(X_test))))
y_pred
```

```{python}
eval_df = pd.DataFrame({
    'y': y_test,
    'y_pred': y_pred,
    'y_pred_rnd': np.round(y_pred)
})
df = eval_df
title='aaa'
```

```{python}
df['y_pred'].rename('correct')
```

```{python}
# correct
correct = df.query('y == y_pred_rnd')['y_pred'].rename('correct')
plt.figure()
correct.plot(kind='kde', title=title+'correct kde', legend='correct')
plt.tight_layout(pad=0.5)
#plt.savefig(os.path.join(outpath, title+'_kde_correct.png'))

# errors
errors = df.query('y != y_pred_rnd')['y_pred'].rename('errors')
errors.plot(kind='density', title=title+'errors kde', legend=True)
plt.tight_layout(pad=0.5)
#plt.savefig(os.path.join(outpath, title+'_kde_errors.png'))

```

```{python}
eval_plot(eval_df)
```

```{python}
from sklearn.neighbors import KernelDensity
```

```{python}
# correct
correct = eval_df.query('y == y_pred_rnd')['y_pred']
# errors
errors = eval_df.query('y != y_pred_rnd')['y_pred']
```

```{python}
cpoints = correct.plot(kind='kde').get_lines()[0].get_xydata()
```

```{python}
epoints = errors.plot(kind='kde').get_lines()[0].get_xydata()
```

```{python}
cpoints[456]
```

```{python}
plt.plot(cpoints)
plt.plot(epoints)
```

```{python}
LineString(LineString(cpoints).intersection(LineString(epoints))).xy
```

```{python}
LineString(epoints)
```

```{python}

from shapely.geometry import LineString
```

```{python}
np.argmin(np.abs(cpoints[:,1] - epoints[:,1]))
```

```{python}
res.get_lines()[0].get_xydata().shape
```

```{python}
kde = KernelDensity(kernel='gaussian', bandwidth=0.75).fit(correct.reshape(-1, 1))
```

```{python}
X_plot = np.linspace(0, 1, 1000)[:, np.newaxis]
X_plot.reshape(-1)
```

```{python}
pd.DataFrame({
    'y': kde.score_samples(X_plot),
    'x': X_plot.reshape(-1)
}).plot(x='x', y='y')
```

```{python}
tl = 0.25
th = 0.65
print('ratio', eval_df.query(f'y_pred <= {tl} or y_pred >= {th}').shape[0] / eval_df.shape[0])
eval_plot(eval_df.query(f'y_pred <= {tl} or y_pred >= {th}'))
```

```{python}
#whole2['cross_nil_p'] = 
whole2['cross_nil_p_lr'] = np.array(
    list(
        map(
            lambda x: x[1],
            clf.predict_proba(
                lr_scaler.transform(whole2[features].values)
            )
        )
    )
)
```

```{python}
whole2['cross_nil_b_lr'] = np.round(whole2['cross_nil_p_lr'])
```

```{python}
print(classification_report(whole2['y'], whole2['cross_nil_b']))
```

```{python}
print(classification_report(whole2['y'], whole2['cross_nil_b_lr']))
```

```{python}
def _myf(x):
    if x['cross_nil_b_lr'] == 0:
        return -1
    else:
        return x['cross_best_candidate']

whole2['cross_best_candidate_nil_lr'] = whole2.apply(_myf, axis=1)
```

```{python}
whole2.query('cross_labels == `cross_best_candidate+nil`').shape[0] / whole2.shape[0]
```

```{python}
whole2.query('cross_labels == `cross_best_candidate_nil_lr`').shape[0] / whole2.shape[0]
```

```{python}
whole2.query('cross_labels != -1 and cross_labels == cross_best_candidate and cross_nil_b == 0').shape[0]  / whole2.shape[0]
```

```{python}
whole2.query('cross_labels != -1 and cross_labels == cross_best_candidate and cross_nil_b == 0')['cross_hamming'].plot(kind='density')
```

```{python}
wrong_nil = whole2.query('cross_labels != -1 and cross_labels == cross_best_candidate and cross_nil_b_lr == 0')
```

```{python}
wrong_nil.shape[0] / whole2.shape[0]
```

```{python}
import textdistance
```

```{python}
dfun = textdistance.hamming.normalized_similarity
```

```{python}
wrong_nil.apply(
    lambda x: dfun(x['mention'], x['cross_best_candidate_title']),
    axis=1
).plot(kind='density')
```

```{python}
wrong_nil['cross_nil_p_lr'].plot(kind='density')
```

```{python}
wrong_nil['cross_nil_p_lr'].plot(kind='density')
```

```{python}
whole2.apply(
    lambda x: dfun(x['mention'], x['cross_best_candidate_title']),
    axis=1
).plot(kind='density')
```

```{python}
whole2['cross_hamming'] = whole2.apply(
    lambda x: textdistance.hamming.normalized_similarity(x['mention'], x['cross_best_candidate_title']),
    axis=1
)
```

```{python}
whole2['bi_hamming'] = whole2.apply(
    lambda x: textdistance.hamming.normalized_similarity(x['mention'], x['bi_best_candidate_title']),
    axis=1
)
```

```{python}
whole2.
```

```{python}
whole2.to_csv('whole2_with_100_10_stats_ds.csv')
```

```{python}
whole2
```

```{python}
from flair.data import Sentence
from flair.models import SequenceTagger

# make a sentence
sentence = Sentence('I love Berlin .')

# load the NER tagger
tagger = SequenceTagger.load('ner')

# run NER over sentence
tagger.predict(sentence)
```

```{python}
# ls
```

```{python}
import pandas as pd
```

```{python}
df = pd.read_csv('whole3_ner_avg_also_correct2.csv', index_col=0)
```

```{python}
df = pd.read_csv('whole6.csv', index_col=0)
```

```{python}
df['src'].value_counts()
```

```{python}
[
    {
        'train': ['dataset_and_preds/AIDA-YAGO2_train.csv'],
        'test': ['dataset_and_preds/AIDA-YAGO2_testa.csv', 'dataset_and_preds/AIDA-YAGO2_testb.csv'],
        'augment': 'no',
        'features': 'all'
    },
    {
        'train': ['dataset_and_preds/AIDA-YAGO2_train.csv'],
        'test': ['dataset_and_preds/AIDA-YAGO2_testa.csv', 'dataset_and_preds/AIDA-YAGO2_testb.csv'],
        'augment': 'augment'
        'features': 'all'
    },
    {
        'train': ['dataset_and_preds/AIDA-YAGO2_train.csv'],
        'test': ['dataset_and_preds/AIDA-YAGO2_testa.csv', 'dataset_and_preds/AIDA-YAGO2_testb.csv'],
        'augment': 'undersample'
        'features': 'all'
    },
]
```

```{python}
df[df['src'].isin(['dataset_and_preds/AIDA-YAGO2_testa.csv', 'dataset_and_preds/AIDA-YAGO2_testb.csv'])]['src'].value_counts()
```

```{python}
isinstance([4.0], list)
```

```{python}
df['y']
```

```{python}
train_df[['avg_ner_per_correct', 'avg_ner_org_correct']].notna().all(axis=1)
```

```{python}
train_df[train_df[['avg_ner_per_correct', 'avg_ner_org_correct']].notna().all(axis=1)].isna().sum()
```

```{python}
train_df.to_csv('whole3_ner_avg_also_correct2.csv')
```

```{python}
list(dataset.columns)
```

```{python}
train_df = train_df.rename(columns={
    'avg_ner_misc': 'avg_ner_misc_cross'
})
```

```{python}
list(train_df.columns)
```

```{python}
# non va bene, serve best candidate
avg_ner_types_correct = train_df.query('bi_best_candidate == bi_labels').groupby('bi_best_candidate')[['ner_per', 'ner_loc', 'ner_org', 'ner_misc']].mean()
avg_ner_types_correct = avg_ner_types_correct.rename(columns={
    'ner_per': 'avg_ner_per_correct_bi',
    'ner_loc': 'avg_ner_loc_correct_bi',
    'ner_org': 'avg_ner_org_correct_bi',
    'ner_misc': 'avg_ner_misc_correct_bi',
})

avg_ner_types = train_df.groupby('bi_best_candidate')[['ner_per', 'ner_loc', 'ner_org', 'ner_misc']].mean()
avg_ner_types = avg_ner_types.rename(columns={
    'ner_per': 'avg_ner_per_bi',
    'ner_loc': 'avg_ner_loc_bi',
    'ner_org': 'avg_ner_org_bi',
    'ner_misc': 'avg_ner_misc_bi',
})

#avg_ner_types[['avg_ner_per', 'avg_ner_loc', 'avg_ner_org', 'avg_ner_misc']] = np.array(list(map(lambda x: (x == x.max()).astype(int), avg_ner_types[['avg_ner_per', 'avg_ner_loc', 'avg_ner_org', 'avg_ner_misc']].values)))

train_df = train_df.join(avg_ner_types_correct, on='bi_best_candidate')
train_df = train_df.join(avg_ner_types, on='bi_best_candidate')
```

```{python}
dataset['src'].value_counts().index.tolist()
```

```{python}
dataset.columns
```

```{python}
dataset.query('(y_pred == 1 and (cross_labels == cross_best_candidate or Wikipedia_title == cross_best_candidate_title)) or (cross_labels == -1 and y_pred == 0)')
```

```{python}
# ls *.csv
```

```{python}
whole2 = pd.read_csv('whole3_ner_avg_also_correct2.csv')
```

```{python}
        features=   [
                'bi_stats_10_max',
                'bi_stats_10_min',
                'bi_stats_10_mean',
                'bi_stats_10_median',
                'bi_stats_10_stdev',
                'bi_hamming',
            ]
```

```{python}
df[df['ner_per'].isna()]['src'].value_counts()
```

```{python}
df[features].isna().sum()
```

```{python}
tdf = pd.read_csv('aida_ner_type_v2.csv', index_col=0)
```

```{python}
tdf.rename(columns={
    'per': 'wiki_per',
    'loc': 'wiki_loc',
    'org': 'wiki_org',
    'misc': 'wiki_misc'
})[['id', 'wiki_per', 'wiki_loc', 'wiki_org', 'wiki_misc']]
```

```{python}
df.merge(tdf, how='left', left_on='cross_best_candidate', right_on='id')[['mention', 'cross_best_candidate', 'title']]
```

```{python}
df = df.merge(tdf.rename(columns={
    'per': 'wiki_per_cross',
    'loc': 'wiki_loc_cross',
    'org': 'wiki_org_cross',
    'misc': 'wiki_misc_cross'
})[['id',
    'wiki_per_cross',
    'wiki_loc_cross',
    'wiki_org_cross',
    'wiki_misc_cross']], how='left', left_on='cross_best_candidate', right_on='id').drop(columns='id')
```

```{python}
df = df.merge(tdf.rename(columns={
    'per': 'wiki_per_bi',
    'loc': 'wiki_loc_bi',
    'org': 'wiki_org_bi',
    'misc': 'wiki_misc_bi'
})[['id',
    'wiki_per_bi',
    'wiki_loc_bi',
    'wiki_org_bi',
    'wiki_misc_bi']], how='left', left_on='bi_best_candidate', right_on='id').drop(columns='id')
```

```{python}
[i for i in list(df.columns) if 'wiki' in i]
```

```{python}
df[['wiki_per_cross',
 'wiki_loc_cross',
 'wiki_org_cross',
 'wiki_misc_cross']].sum(axis=1)
```

```{python}
df[['wiki_per_bi',
 'wiki_loc_bi',
 'wiki_org_bi',
 'wiki_misc_bi']] = df[['wiki_per_bi',
 'wiki_loc_bi',
 'wiki_org_bi',
 'wiki_misc_bi']].apply(lambda x: x/x.sum(), axis=1, result_type='expand')
```

```{python}
df[['wiki_per_bi',
 'wiki_loc_bi',
 'wiki_org_bi',
 'wiki_misc_bi']]
```

```{python}
df[['wiki_per_cross',
 'wiki_loc_cross',
 'wiki_org_cross',
 'wiki_misc_cross']]
```

```{python}
df[['wiki_per_cross',
 'wiki_loc_cross',
 'wiki_org_cross',
 'wiki_misc_cross']].loc[0]/2
```

```{python}
df[['wiki_per_cross',
 'wiki_loc_cross',
 'wiki_org_cross',
 'wiki_misc_cross',
 'wiki_per_bi',
 'wiki_loc_bi',
 'wiki_org_bi',
 'wiki_misc_bi']] = df[['wiki_per_cross',
 'wiki_loc_cross',
 'wiki_org_cross',
 'wiki_misc_cross',
 'wiki_per_bi',
 'wiki_loc_bi',
 'wiki_org_bi',
 'wiki_misc_bi']].astype(float)
```

```{python}
df = df.drop(columns=['wiki_per', 'wiki_loc', 'wiki_org', 'wiki_misc'])
```

```{python}
df.rename(columns={
    'wiki_per': 'wiki_per'
})
```

```{python}
df.to_csv('whole4wikitypes.csv')
```

```{python}
aida = df[df['src'].isin([i for i in df['src'].value_counts().index if 'aida' in i.lower()])]
```

```{python}
[i for i in df['src'].value_counts().index]
```

```{python}
aida['wiki_per_cross'].isna().sum()
```

```{python}
df = pd.read_csv('whole_df5_dists_topk.csv', index_col=0)
```

```{python}
df.columns
```

# stats feat selection

```{python}
import seaborn as sns
```

```{python}
# %matplotlib inline
```

```{python}
cor = df[[
    'bi_stats_100_max',
    'bi_stats_100_mean',
    'bi_stats_100_median',
    'bi_stats_100_stdev',
    'y'
]].corr()
```

```{python}
cor = df[[
    'bi_stats_10_max',
    'bi_stats_10_mean',
    'bi_stats_10_median',
    'bi_stats_10_stdev',
    'y'
]].corr()
```

```{python}
cor = df[[
    'cross_stats_100_max',
    'cross_stats_100_mean',
    'cross_stats_100_median',
    'cross_stats_100_stdev',
    'y'
]].corr()
```

```{python}
cor = df[[
    'cross_stats_10_max',
    'cross_stats_10_mean',
    'cross_stats_10_median',
    'cross_stats_10_stdev',
    'y'
]].corr()
```

```{python}
cor = df[[
    #'cross_stats_10_second',
    #'cross_stats_10_mean',
   #'cross_stats_10_median',
    'cross_stats_2_stdev',
    'cross_stats_3_stdev',
    'cross_stats_4_stdev',
    'cross_stats_5_stdev',
    'cross_stats_6_stdev',
    'cross_stats_7_stdev',
    'cross_stats_8_stdev',
    'cross_stats_9_stdev',
    'cross_stats_10_stdev',
    'cross_stats_100_stdev',
    #'cross_stats_10_min',
    'y'
]].corr()
```

```{python}
import statistics, json
```

```{python}
statistics.stdev(json.loads(df['cross_unsorted_scores'].loc[0]))
```

```{python}
statistics.stdev(json.loads(df['cross_unsorted_scores'].loc[0])[:3])
```

```{python}
list(range(10))[:2]
```

```{python}
#for i in range(15, 100, 5):
for i in range(2, 10):
    df[f'bi_stats_{i}_stdev'] = df['bi_scores'].apply(lambda x: statistics.stdev(json.loads(x)[:i]))
```

```{python}
df['cross_stats_4_mean'] = df['cross_unsorted_scores'].apply(lambda x: statistics.mean(json.loads(x)[:4]))
```

```{python}
import re
```

```{python}
re.match('.*?([0-9]+).*?', 'cross_stats_100_stdev').group(1)
```

```{python}
cor = df[sorted([c for c in df.columns if c.endswith('stdev') and c.startswith('bi')],
       key=lambda x: int(re.match('.*?([0-9]+).*?', x).group(1))) + ['y']].corr()
```

```{python}
df['cross_stats_3_stdev']
```

```{python}
-np.array(range(100))
```

```{python}
pd.DataFrame({
    'a': range(100),
    'b': -np.array(range(100))
}).corr()
```

```{python}
sns.set(style='ticks', palette='Set2')
sns.despine()
```

```{python}
cor['y']
```

```{python}
cor.rename(
    index={i:re.match('.*?([0-9]+).*?', i).group(1) for i in cor.index if re.match('.*?([0-9]+).*?', i)}
).loc[[re.match('.*?([0-9]+).*?', i).group(1) for i in cor.index if i != 'y'],['y']].rename(columns={
    'y': 'y_correlation'
    }).plot(
    title='stdev bi')
```

```{python}
cor.rename(
    index={i:re.match('.*?([0-9]+).*?', i).group(1) for i in cor.index if re.match('.*?([0-9]+).*?', i)}
)
```

```{python}
{c:c.split('_')[-1] for c in cor.columns if c != 'y'}
```

```{python}
sns.heatmap(cor, annot=True)
```

```{python}
sns.heatmap(cor.rename(
    columns={c:c.split('_')[-1] for c in cor.columns if c != 'y'}, 
    index={c:c.split('_')[-1] for c in cor.columns if c != 'y'}), annot = True)
```

```{python}
ista = df['cross_unsorted_scores'].loc[0]
```

```{python}
import json
```

```{python}
ista = json.loads(ista)
```

```{python}
ista = np.array(ista)
```

```{python}
np.abs(ista - ista.mean())
```

```{python}
test = 'hellp'
```

```{python}
import textdistance
```

```{python}
dist_list = [
(    "hamming", textdistance.hamming),
(    "mlipns", textdistance.mlipns),
(    "levenshtein", textdistance.levenshtein),
(    "damerau_levenshtein", textdistance.damerau_levenshtein),
(    "jaro_winkler", textdistance.jaro_winkler),
(    "jaro", textdistance.jaro),
(    "strcmp95", textdistance.strcmp95),
(    "needleman_wunsch", textdistance.needleman_wunsch),
(    "gotoh", textdistance.gotoh),
(    "smith_waterman", textdistance.smith_waterman),
(    "jaccard", textdistance.jaccard),
(    "sorensen", textdistance.sorensen),
(    "sorensen", textdistance.sorensen),
(    "sorensen_dice", textdistance.sorensen_dice),
(    "tversky", textdistance.tversky),
(    "overlap", textdistance.overlap),
(    "tanimoto", textdistance.tanimoto),
(    "cosine", textdistance.cosine),
(    "monge_elkan", textdistance.monge_elkan),
(    "bag", textdistance.bag),
(    "lcsseq", textdistance.lcsseq),
(    "lcsstr", textdistance.lcsstr),
(    "ratcliff_obershelp", textdistance.ratcliff_obershelp),
(    "arith_ncd", textdistance.arith_ncd),
(    "rle_ncd", textdistance.rle_ncd),
(    "bwtrle_ncd", textdistance.bwtrle_ncd),
(    "sqrt_ncd", textdistance.sqrt_ncd),
(    "entropy_ncd", textdistance.entropy_ncd),
(    "bz2_ncd", textdistance.bz2_ncd),
(    "lzma_ncd", textdistance.lzma_ncd),
(    "zlib_ncd", textdistance.zlib_ncd),
(    "mra", textdistance.mra),
(    "editex", textdistance.editex),
(    "prefix", textdistance.prefix),
(    "postfix", textdistance.postfix),
(    "length", textdistance.length),
(    "identity", textdistance.identity),
(    "matrix", textdistance.matrix),
]
```

```{python}
[i for i,_ in dist_list]
```

```{python}
for diststring, dist in dist_list:
    df[diststring] = df.apply(
        lambda x: dist.normalized_similarity(x['mention'], x['cross_best_candidate_title']),
        axis=1
    )
```

```{python}
from bs4 import BeautifulSoup
import requests
```

```{python}
res = requests.get('https://pypi.org/project/textdistance/')
```

```{python}
html = BeautifulSoup(res.text)
```

```{python}
html.find_all('tr')[2].find_all('td')
```

```{python}
[tr.find_all('td')[-1].text for tr in html.find_all('tr') if len(tr.find_all('td')) ==3]
```

```{python}
dists = [tr.find_all('td')[-1].text for tr in html.find_all('tr') if len(tr.find_all('td')) ==3]
```

```{python}
for d in dists:
    print(f'"{d}", textdistance.{d},')
```

```{python}
cord= df[['cross_dist_'+i for i,_ in dist_list]+['y']].rename(columns={'cross_dist_'+i:i for i,_ in dist_list}).corr()
```

```{python}
import seaborn as sns
```

```{python}
df[[i for i,_ in dist_list]+['y']].corr()['y']
```

```{python}
df.corr()['y']
```

```{python}
df[[i for i,_ in dist_list]+['y']].corr().to_csv('images/all_distances_corr_cross.csv')
```

```{python}
cordf = pd.read_csv('images/all_distances_corr_cross.csv', index_col=0)
cordf
```

```{python}
any(cordf['y'] < 0)
```

```{python}
cordf['y'].sort_values(ascending=False).index[0:11]
```

```{python}
cordf_top10 = cordf.loc[['y', 'hamming', 'lcsstr', 'levenshtein', 'damerau_levenshtein',
       'zlib_ncd', 'editex', 'lcsseq', 'mlipns', 'ratcliff_obershelp',
       'jaccard'], ['y', 'hamming', 'lcsstr', 'levenshtein', 'damerau_levenshtein',
       'zlib_ncd', 'editex', 'lcsseq', 'mlipns', 'ratcliff_obershelp',
       'jaccard']]
```

```{python}
cordf_top10
```

```{python}
sns.heatmap(cordf_top10)
```

```{python}
sns.heatmap(df[[i for i,_ in dist_list]+['y']].corr())
```

```{python}
sns.heatmap(cord.loc[['zlib_ncd', 'mlipns', 'ratcliff_obershelp', 'jaccard', 'tversky',
       'hamming', 'jaro', 'y'],['zlib_ncd', 'mlipns', 'ratcliff_obershelp', 'jaccard', 'tversky',
       'hamming', 'jaro', 'y']])
```

```{python}
cord.loc[['zlib_ncd', 'mlipns', 'ratcliff_obershelp', 'jaccard', 'tversky',
       'hamming'],['zlib_ncd', 'mlipns', 'ratcliff_obershelp', 'jaccard', 'tversky',
       'hamming']]
```

```{python}
with open('images/top_distances_corr_cross.tex', 'w') as fd:
    fd.write(cord[['y']].drop(index='y').rename(
    columns={'y':'y_correlation'}).sort_values(
    by='y_correlation', key = lambda x:  np.abs(x), ascending=False).to_latex())
```

```{python}
cord[['y']].drop(index='y').rename(
    columns={'y':'y_correlation'}).sort_values(
    by='y_correlation', key = lambda x:  np.abs(x), ascending=False).to_csv('images/top_distances_corr_cross.csv')
```

```{python}
cord['y'].abs().sort_values(ascending=False)
```

```{python}
{i:'cross_dist_'+i for i,_ in dist_list}
```

```{python}
df = df.rename(columns={i:'cross_dist_'+i for i,_ in dist_list})
```

```{python}
df.to_csv('whole_df5_dists_topk.csv')
```

```{python}
[i for i in df.columns if 'correct' in i]
```

```{python}
aida = df[df['src'].isin([c for c in df['src'].value_counts().index if 'aida' in c.lower()])]
```

```{python}
aida[aida['avg_ner_per_correct_cross'].notna()]['y'].value_counts()
```

```{python}
df[df['src'].isin([c for c in df['src'].value_counts().index if 'aida' in c.lower()])]['avg_ner_per_correct_cross'].notna().sum()
```

```{python}
df[df['src'].isin([c for c in df['src'].value_counts().index if 'aida' in c.lower()])]['y'].value_counts()
```

# encodings for blink test clustering and retrieval by mention

```{python}
# ls ../data/BLINK_benchmark_with_NIL
```

```{python}
import os;os.listdir('../data/BLINK_benchmark_with_NIL')
```

```{python}
encodings_p = ['AIDA-YAGO2_train_encodings.jsonl',
 'AIDA-YAGO2_testb_encodings.jsonl',
 'AIDA-YAGO2_testa_encodings.jsonl']
```

```{python}
aida_p = [
 'AIDA-YAGO2_train.jsonl',
 'AIDA-YAGO2_testb.jsonl',
 'AIDA-YAGO2_testa.jsonl']
```

```{python}
df = pd.read_json('../data/BLINK_benchmark_with_NIL/AIDA-YAGO2_train.jsonl', lines=True)
```

```{python}
df2 = pd.read_json('encodings_all/AIDA-YAGO2_train_encodings.jsonl', lines=True)
```

```{python}
#
```

```{python}
import textdistance
```

```{python}

```
