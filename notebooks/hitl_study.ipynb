{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c24ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as  np\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "sns.set(style='ticks', palette='Set2')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3590dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle('whole7.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b419835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_new_out_ablation_1001/aida_under_all_max_stats10_ner_wiki_model.pickle', 'rb') as fd:\n",
    "    clf = pickle.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac98539",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataset[dataset['src'].isin(['dataset_and_preds/AIDA-YAGO2_train.csv'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3027255",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = dataset[dataset['src'].isin(['dataset_and_preds/AIDA-YAGO2_testa.csv', 'dataset_and_preds/AIDA-YAGO2_testb.csv'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047e656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features =  [\n",
    "                'cross_stats_10_max',\n",
    "                'cross_stats_10_mean',\n",
    "                'cross_stats_10_median',\n",
    "                'cross_stats_10_stdev',\n",
    "                'bi_stats_10_max',\n",
    "                'bi_stats_10_mean',\n",
    "                'bi_stats_10_median',\n",
    "                'bi_stats_10_stdev',\n",
    "                'ner_per',\n",
    "                'ner_loc',\n",
    "                'ner_org',\n",
    "                'ner_misc',\n",
    "                'wiki_per_cross',\n",
    "                'wiki_loc_cross',\n",
    "                'wiki_org_cross',\n",
    "                'wiki_misc_cross',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f1c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_whom = 'y_cross'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7348391",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_shape_original = train_df.shape[0]\n",
    "test_df_shape_original = test_df.shape[0]\n",
    "\n",
    "train_df = train_df[train_df[features].notna().all(axis=1)]\n",
    "test_df = test_df[test_df[features].notna().all(axis=1)]\n",
    "\n",
    "train_df_shape_notna = train_df.shape[0]\n",
    "test_df_shape_notna = test_df.shape[0]\n",
    "\n",
    "print('undersampling...')\n",
    "\n",
    "train_df_0 = train_df.query(f'{y_whom} == 0')\n",
    "train_df_1 = train_df.query(f'{y_whom} == 1')\n",
    "\n",
    "train_df_1 = train_df_1.sample(frac=1).iloc[:train_df_0.shape[0]]\n",
    "train_df = pd.concat([train_df_0, train_df_1]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02a8b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_shape_actual = train_df.shape[0]\n",
    "test_df_shape_actual = test_df.shape[0]\n",
    "\n",
    "df_size_report = pd.DataFrame({\n",
    "    'train': [train_df_shape_original, train_df_shape_notna, train_df_shape_actual],\n",
    "    'test': [test_df_shape_original, test_df_shape_notna, test_df_shape_actual]\n",
    "}, index=['original', 'notna', 'actual']).to_markdown()\n",
    "print(df_size_report)\n",
    "\n",
    "print(pd.DataFrame(train_df[y_whom].value_counts()).to_markdown())\n",
    "\n",
    "X_train = train_df[features].values\n",
    "y_train = train_df[y_whom].values\n",
    "\n",
    "X_test = test_df[features].values\n",
    "y_test = test_df[y_whom].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c529cc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(list(map(lambda x: x[1], clf.predict_proba(X_test))))\n",
    "y_pred_round = np.round(y_pred)\n",
    "\n",
    "test_df['y_pred_round'] = y_pred_round\n",
    "test_df['y_pred'] = y_pred\n",
    "\n",
    "bi_baseline = test_df.query('bi_labels == bi_best_candidate or Wikipedia_title == bi_best_candidate_title').shape[0]\n",
    "cross_baseline = test_df.query('cross_labels == cross_best_candidate or Wikipedia_title == cross_best_candidate_title').shape[0]\n",
    "\n",
    "bi_acc = test_df.query('(y_pred_round == 1 and (bi_labels == bi_best_candidate or Wikipedia_title == bi_best_candidate_title)) or (bi_labels == -1 and y_pred_round == 0)').shape[0]\n",
    "cross_acc = test_df.query('(y_pred_round == 1 and (cross_labels == cross_best_candidate or Wikipedia_title == cross_best_candidate_title)) or (cross_labels == -1 and y_pred_round == 0)').shape[0]\n",
    "\n",
    "_classification_report = classification_report(y_test, y_pred_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecbd88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5bd3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'oracle_1'\n",
    "test = 'aida_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33e5ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_report = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0933c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(0.5-i/20, 0.5+i/20) for i in range(11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c3367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = [\n",
    " (0.6, 0.4), # no human validation\n",
    " (0.45, 0.55),\n",
    " (0.4, 0.6),\n",
    " (0.35, 0.65),\n",
    " (0.3, 0.7),\n",
    " (0.25, 0.75),\n",
    " (0.2, 0.8),\n",
    " (0.15, 0.85),\n",
    " (0.1, 0.9),\n",
    " (0.05, 0.95),\n",
    " #(0.0, 1.0) # all validated\n",
    "]\n",
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f25d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tl, th in intervals:\n",
    "    print(tl ,th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605eef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_report = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbab9f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173ebdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['y_test'] = test_df[y_whom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c496c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oracle corrects in [0.25, 0.75]\n",
    "    # TODO maybe look for a better way to get them (e.g. correct-error kde intersections ?)\n",
    "#tl = 0.25\n",
    "#th = 0.75\n",
    "for tl, th in intervals:\n",
    "    oracle_original_shape = test_df.shape[0]\n",
    "    \n",
    "    \n",
    "    test_df_oracle = test_df.query(f'y_pred < {tl} or y_pred > {th}')\n",
    "\n",
    "\n",
    "    _classification_report_oracle = classification_report(test_df_oracle['y_test'], test_df_oracle['y_pred_round'])\n",
    "\n",
    "\n",
    "    bi_acc_oracle = test_df_oracle.query(\n",
    "        '(y_pred_round == 1 and (bi_labels == bi_best_candidate or Wikipedia_title == bi_best_candidate_title)) or '\n",
    "        '(bi_labels == -1 and y_pred_round == 0)').shape[0]\n",
    "    cross_acc_oracle = test_df_oracle.query(\n",
    "        '(y_pred_round == 1 and '\n",
    "        '(cross_labels == cross_best_candidate or Wikipedia_title == cross_best_candidate_title))'\n",
    "        ' or (cross_labels == -1 and y_pred_round == 0)').shape[0]\n",
    "\n",
    "    bi_acc_oracle_correcting_nel = test_df_oracle.query(\n",
    "        '(y_pred_round == 1 and (bi_labels == bi_best_candidate or Wikipedia_title == bi_best_candidate_title))'\n",
    "        ' or (bi_labels != bi_best_candidate and y_pred_round == 0)').shape[0]\n",
    "    cross_acc_oracle_correcting_nel = test_df_oracle.query(\n",
    "        '(y_pred_round == 1 and '\n",
    "        '(cross_labels == cross_best_candidate or Wikipedia_title == cross_best_candidate_title))'\n",
    "        ' or (cross_labels != cross_best_candidate and y_pred_round == 0)').shape[0]\n",
    "\n",
    "    _f1_0 = f1_score(y_test, y_pred_round, pos_label=0)\n",
    "    _f1_1 = f1_score(y_test, y_pred_round, pos_label=1)\n",
    "\n",
    "    _macro_avg_f1 = (_f1_0 + _f1_1) / 2\n",
    "\n",
    "    _f1_0_oracle = f1_score(test_df_oracle['y_test'], test_df_oracle['y_pred_round'], pos_label=0)\n",
    "    _f1_1_oracle = f1_score(test_df_oracle['y_test'], test_df_oracle['y_pred_round'], pos_label=1)\n",
    "\n",
    "    _macro_avg_f1_oracle = (_f1_0_oracle + _f1_1_oracle) / 2\n",
    "    \n",
    "    oracle_ratio = 1 - (test_df_oracle.shape[0] / oracle_original_shape)\n",
    "    \n",
    "    test_df_oracle_random = test_df.sample(n=test_df_oracle.shape[0], random_state=1244)\n",
    "    \n",
    "    bi_acc_oracle_random = test_df_oracle_random.query(\n",
    "        '(y_pred_round == 1 and (bi_labels == bi_best_candidate or Wikipedia_title == bi_best_candidate_title)) or '\n",
    "        '(bi_labels == -1 and y_pred_round == 0)').shape[0]\n",
    "    cross_acc_oracle_random = test_df_oracle_random.query(\n",
    "        '(y_pred_round == 1 and '\n",
    "        '(cross_labels == cross_best_candidate or Wikipedia_title == cross_best_candidate_title))'\n",
    "        ' or (cross_labels == -1 and y_pred_round == 0)').shape[0]\n",
    "\n",
    "    bi_acc_oracle_random_correcting_nel = test_df_oracle_random.query(\n",
    "        '(y_pred_round == 1 and (bi_labels == bi_best_candidate or Wikipedia_title == bi_best_candidate_title))'\n",
    "        ' or (bi_labels != bi_best_candidate and y_pred_round == 0)').shape[0]\n",
    "    cross_acc_oracle_random_correcting_nel = test_df_oracle_random.query(\n",
    "        '(y_pred_round == 1 and '\n",
    "        '(cross_labels == cross_best_candidate or Wikipedia_title == cross_best_candidate_title))'\n",
    "        ' or (cross_labels != cross_best_candidate and y_pred_round == 0)').shape[0]\n",
    "    \n",
    "    _f1_0_oracle_random = f1_score(test_df_oracle_random['y_test'], test_df_oracle_random['y_pred_round'], pos_label=0)\n",
    "    _f1_1_oracle_random = f1_score(test_df_oracle_random['y_test'], test_df_oracle_random['y_pred_round'], pos_label=1)\n",
    "\n",
    "    _macro_avg_f1_oracle_random = (_f1_0_oracle_random + _f1_1_oracle_random) / 2\n",
    "\n",
    "    assert test_df_oracle.shape[0] == test_df_oracle.shape[0]\n",
    "    \n",
    "    csv_report = csv_report.append({\n",
    "        'name': name,\n",
    "        'th': th,\n",
    "        'tl': tl,\n",
    "        'bi_baseline': bi_baseline / test_df_shape_actual,\n",
    "        'cross_baseline': cross_baseline / test_df_shape_actual,\n",
    "        'bi_acc': bi_acc / test_df_shape_actual,\n",
    "        'cross_acc': cross_acc / test_df_shape_actual,\n",
    "        'bi_acc_adjusted': bi_acc / test_df_shape_original,\n",
    "        'cross_acc_adjusted': cross_acc / test_df_shape_original,\n",
    "        '0-f1': _f1_0,\n",
    "        '1-f1': _f1_1,\n",
    "        'macro-avg-f1': _macro_avg_f1,\n",
    "        'oracle_ratio': oracle_ratio,\n",
    "        'bi_acc_oracle': bi_acc_oracle / test_df_oracle.shape[0],\n",
    "        'cross_acc_oracle': cross_acc_oracle / test_df_oracle.shape[0],\n",
    "        'bi_acc_oracle_overall': (bi_acc_oracle + oracle_original_shape - test_df_oracle.shape[0] )/ test_df.shape[0],\n",
    "        'cross_acc_oracle_overall': (cross_acc_oracle + oracle_original_shape - test_df_oracle.shape[0] ) / test_df.shape[0],\n",
    "        'bi_acc_oracle_correcting_nel': bi_acc_oracle_correcting_nel / test_df_oracle.shape[0],\n",
    "        'cross_acc_oracle_correcting_nel': cross_acc_oracle_correcting_nel / test_df_oracle.shape[0],\n",
    "        'bi_acc_oracle_correcting_nel_overall': (bi_acc_oracle_correcting_nel+ oracle_original_shape - test_df_oracle.shape[0] ) / test_df.shape[0],\n",
    "        'cross_acc_oracle_correcting_nel_overall': (cross_acc_oracle_correcting_nel + oracle_original_shape - test_df_oracle.shape[0] )/ test_df.shape[0],\n",
    "        '0-f1-oracle': _f1_0_oracle,\n",
    "        '1-f1-oracle': _f1_1_oracle,\n",
    "        'macro-avg-f1-oracle': _macro_avg_f1_oracle,\n",
    "        'bi_acc_oracle_random': bi_acc_oracle_random / test_df_oracle_random.shape[0],\n",
    "        'cross_acc_oracle_random': cross_acc_oracle_random / test_df_oracle_random.shape[0],\n",
    "        'bi_acc_oracle_random_overall': (bi_acc_oracle_random + oracle_original_shape - test_df_oracle.shape[0] )/ test_df.shape[0],\n",
    "        'cross_acc_oracle_random_overall': (cross_acc_oracle_random + oracle_original_shape - test_df_oracle.shape[0] )/ test_df.shape[0],\n",
    "        'bi_acc_oracle_random_correcting_nel_overall': (bi_acc_oracle_random_correcting_nel + oracle_original_shape - test_df_oracle.shape[0] )/ test_df.shape[0],\n",
    "        'cross_acc_oracle_random_correcting_nel_overall': (cross_acc_oracle_random_correcting_nel+ oracle_original_shape - test_df_oracle.shape[0] ) / test_df.shape[0],\n",
    "        'bi_acc_oracle_random_correcting_nel': bi_acc_oracle_random_correcting_nel / test_df_oracle_random.shape[0],\n",
    "        'cross_acc_oracle_random_correcting_nel': cross_acc_oracle_random_correcting_nel / test_df_oracle_random.shape[0],\n",
    "        '0-f1-oracle_random': _f1_0_oracle_random,\n",
    "        '1-f1-oracle_random': _f1_1_oracle_random,\n",
    "        'macro-avg-f1-oracle_random': _macro_avg_f1_oracle_random,\n",
    "    }, ignore_index=True)\n",
    "\n",
    "    print(_classification_report)\n",
    "\n",
    "    print('-- Performances over test set:', test, '--')\n",
    "    print('Bi baseline:', bi_baseline / test_df_shape_actual)\n",
    "    print('Cross baseline:', cross_baseline / test_df_shape_actual)\n",
    "    print('Bi acc:', bi_acc / test_df_shape_actual)\n",
    "    print('Cross acc:', cross_acc / test_df_shape_actual)\n",
    "    print('Bi acc adjusted:', bi_acc / test_df_shape_original)\n",
    "    print('Cross acc adjusted:', cross_acc / test_df_shape_original)\n",
    "\n",
    "    print(f'-- Oracle HITL evaluation when y_pred in [{tl}, {th}]')\n",
    "    print('Ratio to human validator:', 1 - (test_df_oracle.shape[0] / oracle_original_shape))\n",
    "    print(_classification_report_oracle)\n",
    "\n",
    "    print('Bi acc oracle:', bi_acc_oracle / test_df_oracle.shape[0])\n",
    "    print('Cross acc oracle:', cross_acc_oracle / test_df_oracle.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a565548",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_report.loc[10] = [1]*csv_report.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f460cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d129cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_report.plot(x = 'oracle_ratio', y=[\n",
    "    'cross_acc_oracle', 'cross_acc_oracle_correcting_nel', '0-f1-oracle', '1-f1-oracle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd70d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_report[['oracle_ratio', 'cross_acc_oracle', 'cross_acc_oracle_overall', 'cross_acc_oracle_random_overall', 'cross_acc_oracle_correcting_nel', '0-f1-oracle', '1-f1-oracle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b470fcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_report = csv_report[[\n",
    "    'oracle_ratio', 'cross_acc_oracle', 'cross_acc_oracle_overall',\n",
    "    'cross_acc_oracle_random', 'cross_acc_oracle_random_overall', 'cross_acc_oracle_correcting_nel',\n",
    "    'cross_acc_oracle_correcting_nel_overall', '0-f1-oracle', '1-f1-oracle',\n",
    "    'cross_acc_oracle_random_correcting_nel',\n",
    "    'cross_acc_oracle_random_correcting_nel_overall'\n",
    "]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffadbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_report = oracle_report*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2380d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_report['interval to HITL'] = csv_report[['tl', 'th']].apply(lambda x: f'[{x.tl:.2f}, {x.th:.2f}]', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb357a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_report = oracle_report.rename(columns={\n",
    "    'oracle_ratio': 'Ratio to HITL',\n",
    "    'cross_acc_oracle_random':'Acc Random',\n",
    "    'cross_acc_oracle':'Acc',\n",
    "    'cross_acc_oracle_correcting_nel': 'Acc-mit',\n",
    "    'cross_acc_oracle_random_overall':'Acc Random Overall',\n",
    "    'cross_acc_oracle_overall':'Acc Overall',\n",
    "    'cross_acc_oracle_correcting_nel_overall': 'Acc-mit Overall',\n",
    "    'cross_acc_oracle_random_correcting_nel': 'Acc-mit Random',\n",
    "    'cross_acc_oracle_random_correcting_nel_overall': 'Acc-mit Random Overall',\n",
    "    '0-f1-oracle': '0-f1',\n",
    "    '1-f1-oracle': '1-f1'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0566707",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi = 200)\n",
    "oracle_report.plot(x='Ratio to HITL', y=[\n",
    "    'Acc-mit Overall', 'Acc-mit Random Overall', 'Acc Overall', 'Acc Random Overall', \n",
    "], ax = plt.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f8bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi = 100)\n",
    "#oracle_report.plot(x='Ratio to HITL', y=['Accuracy Random', 'Accuracy', 'Accuracy**', '0-f1', '1-f1'], ax = plt.gca())\n",
    "oracle_report.plot(x='Ratio to HITL', y=['1-f1', 'Acc**', '0-f1',  'Acc','Acc Random',], ax = plt.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae92754",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(oracle_report.round(decimals=1)[[\n",
    "    'interval to HITL', 'Ratio to HITL', 'Acc Random Overall', 'Acc Random',\n",
    "    'Acc Overall', 'Acc', 'Acc** Random Overall', 'Acc** Random',\n",
    "    'Acc** Overall','Acc**',  '0-f1', '1-f1']\n",
    "                               ].to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807280ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
