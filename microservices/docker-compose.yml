version: "3"
services:

  tint:
    restart: $RESTART_POLICY
    image: rpozzi/tint
    # build:
    #   context: tint
    #   dockerfile: Dockerfile
    ports:
      - $LISTEN_TINT:8012

  postgres:
    restart: $RESTART_POLICY
    image: postgres:14
    environment:
      POSTGRES_PASSWORD: $POSTGRES_PASSWORD
    volumes:
      - ./postgres/data:/var/lib/postgresql/data
      - "./postgres/init.sql:/docker-entrypoint-initdb.d/init.sql"
    ports:
      - $LISTEN_POSTGRES:5432

  mongo:
    restart: $RESTART_POLICY
    image: mongo:4.4.6 # mongo 5 requires cpu supports AVX
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: $MONGO_ROOT_PASSWORD
      MONGO_INITDB_DATABASE: main
      MONGO_INITDB_USERNAME: usr
      MONGO_INITDB_PASSWORD: $MONGO_PASSWORD
    ports:
      - $LISTEN_MONGO:27017
    volumes:
      - ./mongo/data:/data/db
      - ./mongo/initdb.d:/docker-entrypoint-initdb.d/

  documents:
    restart: $RESTART_POLICY
    build: documents
    ports:
      - $LISTEN_DOCUMENTS:3001
    environment:
      PORT: 3001
      ENABLE_AUTH: false
      MONGO: mongodb://usr:$MONGO_PASSWORD@mongo:27017/main

  biencoder:
    restart: $RESTART_POLICY
    #image: rpozzi/blink_biencoder
    build:
      context: ./biencoder
      dockerfile: Dockerfile
    volumes:
      - ${LOCAL_WORKSPACE_FOLDER}/models:/home/app/models
    ports:
      - $LISTEN_BIENCODER:80
    environment:
      PYTHONPATH: /home/app
      BIENCODER_MODEL: $BIENCODER_MODEL
      BIENCODER_CONFIG: $BIENCODER_CONFIG
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [ gpu ]
    # command: python main.py --host 0.0.0.0 --port 80 --biencoder_model $BIENCODER_MODEL --biencoder_config $BIENCODER_CONFIG

  indexer:
    restart: $RESTART_POLICY
    # image: rpozzi/blink_indexer
    build:
        context: ./indexer
        dockerfile: Dockerfile
    volumes:
      - ${LOCAL_WORKSPACE_FOLDER}/models:/home/app/models
    environment:
      INDEXER_INDEX: $INDEXER_INDEX
      POSTGRES_PASSWORD: $POSTGRES_PASSWORD
      INDEXER_VECTOR_SIZE: $INDEXER_VECTOR_SIZE
      INDEXER_LANGUAGE: $INDEXER_LANGUAGE
    ports:
      - $LISTEN_INDEXER:80
    depends_on:
      - postgres
    # command: python main.py --host 0.0.0.0 --port 80 --index $INDEXER_INDEX --postgres postgres://postgres:$POSTGRES_PASSWORD@postgres:5432/postgres --vector-size $INDEXER_VECTOR_SIZE --language $INDEXER_LANGUAGE

  nilcluster:
    restart: $RESTART_POLICY
    #image: rpozzi/blink_nilcluster
    build:
        context: ./nilcluster
        dockerfile: Dockerfile
    ports:
      - $LISTEN_NILCLUSTER:80
    # command: python main.py --host 0.0.0.0 --port 80

  nilpredictor:
    restart: $RESTART_POLICY
    #image: rpozzi/blink_nilpredictor
    build:
        context: ./nilpredictor
        dockerfile: Dockerfile
    volumes:
      - ${LOCAL_WORKSPACE_FOLDER}/models:/home/app/models
    environment:
      NILPREDICTOR_ARGS: $NILPREDICTOR_ARGS
    ports:
      - $LISTEN_NILPREDICTOR:80
    # command: python main.py --host 0.0.0.0 --port 80 $NILPREDICTOR_ARGS

  pipeline:
    restart: $RESTART_POLICY
    build: pipelinehelper
    ports:
      - $LISTEN_PIPELINE:80
    environment:
      PIPELINE_ADDRESS: $PIPELINE_ADDRESS
    # command: python main.py --host 0.0.0.0 --port 80 --api-baseurl http://$LOCAL_IP

    # not used
    # recognition:
    #   build:
    #       context: ./recognition
    #       dockerfile: Dockerfile
    #   expose:
    #     - 30303
    #   ports:
    #     - 30303:80
    #   command: python -m microservices.nilpredictor --host 0.0.0.0 --port 80 --nil-bi-model output/feature_ablation_study_ita/max_leve_model.pickle --nil-bi-features 'max_bi,levenshtein'
  spacyner:
    restart: $RESTART_POLICY
    build: ./spacyner
    environment:
      SPACY_MODEL: $SPACY_MODEL
      SPACY_TAG: $SPACY_TAG
    ports:
      - $LISTEN_SPACYNER:80
    volumes:
      - ${LOCAL_WORKSPACE_FOLDER}/models:/home/app/models
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [ gpu ]
    # command: python __main__.py --host 0.0.0.0 --port 80 --model $SPACY_MODEL --tint http://tint:8012/tint

  tintner:
    restart: $RESTART_POLICY
    build: ./tintner
    ports:
      - $LISTEN_TINTNER:80
    # command: python __main__.py --host 0.0.0.0 --port 80 --model $SPACY_MODEL --tint http://tint:8012/tint

  caddy:
    restart: $RESTART_POLICY
    image: caddy:2
    ports:
      - "$CADDY_LISTEN_HTTP:80"
      - "$CADDY_LISTEN_HTTPS:443"
    volumes:
      - ./caddy/Caddyfile:/etc/caddy/Caddyfile
      - ./caddy/Caddyfile.d:/etc/caddy/Caddyfile.d
      - ./caddy/Caddyfile.main.d:/etc/caddy/Caddyfile.main.d
      - ./caddy/pwdfile:/etc/caddy/pwdfile
      - ./caddy/site:/srv
      - ./caddy/data:/data
      - ./caddy/config:/config
    environment:
      # fully qualified domain name
      FQDN: "$FQDN"
      LOCAL_IP: "$LOCAL_IP"

  ui:
    build: giustizia-ui
    ports:
      - 127.0.0.1:8080:3000
    environment:
      ACCESS_USERNAME: $UI_ACCESS_USERNAME
      ACCESS_PASSWORD: $UI_ACCESS_PASSWORD
      API_BASE_URI: ${PIPELINE_ADDRESS}/api
      API_USERNAME: ""
      API_PASSWORD: ""
      NEXTAUTH_SECRET: $UI_NEXTAUTH_SECRET
      NEXTAUTH_URL: $UI_NEXTAUTH_URL
      NEXT_PUBLIC_BASE_PATH: $UI_NEXT_PUBLIC_BASE_PATH
      NEXT_PUBLIC_FULL_PATH: $UI_NEXT_PUBLIC_FULL_PATH
